# Inventory Service â€” Frontend

A zero-dependency, vanilla HTML/CSS/JS dashboard that puts a visual face on every feature of the Rust backend. No build step, no framework, no install â€” just open a browser.

---

## Quick Start

The backend must be running on `http://localhost:3000` before you open the frontend.

```bash
# Terminal 1 â€” start the backend
cd backend
cargo run
# (or: docker compose up --build from the project root)

# Terminal 2 â€” serve the frontend
cd frontend
python3 -m http.server 8080
```

Then open **http://localhost:8080** in your browser.

> **Why a server instead of opening the file directly?**
> Browsers block `fetch()` calls from `file://` pages. Any local HTTP server works â€” `python3 -m http.server`, `npx serve`, VS Code Live Server, etc.

---

## File Structure

```
frontend/
â”œâ”€â”€ index.html   â€” Page structure, all 8 sections, 2 modals
â”œâ”€â”€ style.css    â€” Dark-theme design system, all component styles
â”œâ”€â”€ app.js       â€” All API calls, render logic, event wiring
â””â”€â”€ package.json â€” Optional npm scripts (npx serve / python3)
```

**No build tools. No dependencies. No node_modules.**
Everything runs directly in the browser using the native `fetch` API.

---

## Pages

### ðŸ“Š Dashboard

The landing page. Loads automatically on startup.

- **Health indicator** in the sidebar (green dot = backend online, red = offline, re-checks every 30 s)
- **Three stat cards** showing live sizes of `HashSet`, `IndexSet`, and `BTreeSet` in memory
- **Last benchmark summary** â€” winners for insert, lookup, and iterate with timestamps
- **Quick-action buttons** to jump straight to Seed, Benchmark, Set Inspector, or Products

---

### ðŸ“¦ Products

Full CRUD interface for the `products` table.

**Filters** (all applied live on change):
- Category dropdown (all 15 seeded categories)
- Min / Max price in dollars (converted to cents automatically)
- Page size: 25 / 50 / 100 / 500

**Table columns:** truncated ID Â· name Â· category badge Â· price Â· quantity Â· created date Â· actions

**Actions per row:**
- **View** â€” opens a modal with all product fields plus a live **per-set lookup timing panel** showing how long `HashSet`, `IndexSet`, and `BTreeSet` each took to find this product (in Âµs), and whether it was found in each set
- **Edit** â€” pre-fills the create form with current values; submits a `PUT`
- **Delete** â€” confirmation prompt, then `DELETE`; table reloads instantly

**New Product button** â€” modal form with name, category select, price (cents), quantity, and optional description.

---

### â†© Devolutions

Product return history.

**Left panel â€” Return History table:**
- Joined view: devolution ID, product name, category, quantity, reason, returned-at timestamp

**Right panel â€” Record a Return form:**
- Product dropdown auto-populated from the database (up to 500 products, shows name + price)
- Quantity, reason (text input with a pre-filled datalist of common reasons), optional returned-at datetime picker
- Submits `POST /api/devolutions`; table reloads on success

---

### ðŸŒ± Seed Data

Bulk-insert random products generated by the backend seeder.

- **Slider** from 100 to 50 000 with a live count display
- **Quick buttons:** 100 Â· 1 k Â· 5 k Â· 10 k Â· 25 k Â· 50 k (click to jump the slider)
- **Seed button** â€” `POST /api/seed?count=N`
- **Result card** on success:
  - Seeded count
  - Total products now in the database
  - Seed time (ms)
  - Set sync time (ms) â€” how long it took to load all products into all three in-memory sets

**Danger Zone** (bottom of the page):

A red-bordered card with a **ðŸ—‘ Clear All Data** button. Clicking it shows a browser confirmation dialog before firing `DELETE /api/reset`. On success it displays:
- Number of products deleted from the database
- Confirmation that all three in-memory sets were cleared
- Confirmation that accumulated metrics were cleared

Devolutions are removed automatically via the database cascade. This is the only way to fully reset the service to a blank state without restarting the server.

---

### âš¡ Benchmark

The core feature â€” runs `SetManager::run_benchmark()` against all products in the database and displays the results visually.

**Buttons:**
- **â–¶ Run Benchmark** â€” `POST /api/benchmark/run` (may take a moment on large datasets)
- **â†º Reload Last** â€” `GET /api/benchmark/report` â€” restores the last run without re-running

**Results:**

Three color-coded cards, one per set type:

| Card element | Description |
|---|---|
| Colored top border | Blue = HashSet Â· Green = IndexSet Â· Purple = BTreeSet |
| ðŸ† Winner badges | Shown on the card that won each category |
| Description | Plain-English summary of the set's characteristics |
| Bar charts | Proportional bars for insert / lookup hit / lookup miss / iterate all / remove half â€” shorter = faster |
| Exact values | ms for bulk ops, Âµs for single lookups |
| Order indicator | âœ… guaranteed order or ðŸ”€ arbitrary, with order type label |
| Iteration sample | Expandable list of the first 10 names iterated â€” proves order behavior |

Below the cards, an expandable **ASCII Table** section shows the raw terminal output.

---

### ðŸ” Set Inspector

A live snapshot of the three in-memory sets â€” the clearest way to see iteration order differences.

Calls `GET /api/benchmark/sets/status` and renders three columns:

| Column | Color | Order |
|---|---|---|
| HashSet | Blue | ðŸ”€ Arbitrary (hash-based) |
| IndexSet | Green | âœ… Insertion order (FIFO) |
| BTreeSet | Purple | âœ… Alphabetical by name |

Each column shows:
- Set name, optional subtitle (e.g. "LinkedHashSet equivalent")
- Live element count badge
- Order guarantee label
- The **first 5 items** currently in the set, numbered, with truncated UUID
- The backend's note explaining why the order is what it is

> Seed data, run a benchmark to sync the sets, then come here to see the difference directly.

---

### ðŸ’ª Stress Test

Simulates concurrent API load using `tokio::JoinSet` on the backend.

**Configuration form:**
- **Concurrency** (1â€“200): number of virtual users running in parallel
- **Ops per user** (1â€“1000): operations each user performs
- **Pre-seed count** (optional): seeds N products before the run starts

**Operation mix (backend-defined):** 50% reads Â· 25% creates Â· 15% updates Â· 10% deletes
Deletes only target products created *during the same run* â€” pre-existing seeded data is never touched.

**Result sections:**

| Section | What it shows |
|---|---|
| Top stat cards | Throughput (ops/s), total elapsed, concurrency config, error count |
| Latency | MIN / AVG / P95 / P99 / MAX in ms |
| Operations breakdown | Count + percentage + avg latency for reads, creates, updates, deletes |
| Set performance under load | Total ns spent on HashSet/IndexSet/BTreeSet inserts, lookups, and removes during the run |
| ASCII summary | Expandable raw terminal table |

---

### ðŸ“ˆ Metrics

Aggregated timing data accumulated across **all** benchmark runs. Metrics persist until **ðŸ—‘ Clear All Data** is used on the Seed Data page.

**Header:** total entry count + **â¬‡ CSV** download button

**Table** â€” one row per `(operation, set_type)` pair:

| Column | Description |
|---|---|
| Operation | `insert_all`, `lookup_hit`, `lookup_miss`, `iterate_all`, `remove_half` |
| Set Type | HashSet / IndexSet / BTreeSet |
| Samples | Number of timed observations |
| Avg / P50 / P95 / P99 (Âµs) | Latency distribution |
| Avg (ms) | Same average in ms for larger ops |

**CSV download** â€” calls `GET /api/benchmark/export/csv` and triggers a browser file save (`benchmark_metrics.csv`).

**Raw ASCII Table** â€” expandable section with the backend's own formatted output.

---

## Design System

Dark theme built entirely with CSS custom properties â€” no external UI library.

| Token | Value | Used for |
|---|---|---|
| `--bg` | `#0d1117` | Page background |
| `--surface` | `#161b22` | Cards, sidebar |
| `--surface2` | `#21262d` | Table headers, inputs, set items |
| `--border` | `#30363d` | All borders |
| `--accent` | `#6366f1` | Primary buttons, active nav |
| `--blue` | `#58a6ff` | HashSet color |
| `--green` | `#3fb950` | IndexSet color, success states |
| `--purple` | `#a78bfa` | BTreeSet color |
| `--yellow` | `#d29922` | Winner badges, warnings |
| `--red` | `#f85149` | Errors, delete actions |

**Components:** stat cards Â· filterable tables with pagination Â· modal dialogs Â· toast notifications Â· proportional bar charts Â· collapsible `<details>` sections Â· color-coded op breakdown cards.

---

## Backend Dependency

The frontend calls these backend endpoints directly via `fetch`:

| Page | Endpoints used |
|---|---|
| Dashboard | `GET /health`, `GET /api/benchmark/sets/status`, `GET /api/benchmark/report` |
| Products | `GET /api/products`, `GET /api/products/:id`, `POST /api/products`, `PUT /api/products/:id`, `DELETE /api/products/:id` |
| Devolutions | `GET /api/devolutions`, `POST /api/devolutions` |
| Seed | `POST /api/seed?count=N`, `DELETE /api/reset` |
| Benchmark | `POST /api/benchmark/run`, `GET /api/benchmark/report` |
| Set Inspector | `GET /api/benchmark/sets/status` |
| Stress Test | `POST /api/stress-test` |
| Metrics | `GET /api/benchmark/export/json`, `GET /api/benchmark/export/csv` |

The backend runs `CorsLayer::permissive()`, so cross-origin requests from `localhost:8080` are accepted with no additional configuration.

---

## Recommended Workflow

```
1. Start the backend          cargo run  (or docker compose up)
2. Serve the frontend         python3 -m http.server 8080
3. Open http://localhost:8080
4. Go to Seed Data            â†’ seed 5 000 products
5. Go to Benchmark            â†’ click Run Benchmark
6. Go to Set Inspector        â†’ observe the three different orders live
7. Click View on any product  â†’ see per-set lookup times in nanoseconds
8. Go to Stress Test          â†’ run 20 users Ã— 100 ops
9. Go to Metrics              â†’ download the CSV for offline analysis
```
